# The-Meditations

# Foreword
I hope that when I look back at this repo upon my PhD graduation, I will feel that my time hasn't been wasted.

Should the research model of robots follow human behavior? Is language actually an essential input component for robots? And what truly constitutes a robot's ability to solve complex tasks?
Someone took their dog on a trip to the remote countryside, but the dog got lost halfway—surprisingly, it found its way back home by itself later. Yet what kind of ability does this dog’s "wayfinding" actually demonstrate?
If I were forced to decouple and replicate this kind of "old horse knowing the way" - like ability of the dog onto a robot, by analogy with existing technologies, I might consider it a form of VXA. Here, the "X" is not "L" (Language), but input from other modalities, such as scent, magnetic field, or something else.
![Alt Text](img/dog_backhome.jpg)
<p align="center">Fig. A New Hampshire dog is safely back home after 32 days on the run https://www.youtube.com/watch?v=3n7ockygSHg.</p>

It is now very popular to analyze problems using the first principles. When assigning a task to a robot or an autonomous vehicle, people tend to define the problem and set constraints (FORMULATION) in the same way humans solve problems themselves. In my view, the advantage of this approach is that treating humans as a research method or object is a more natural and convenient way to proceed. However, could this method lead to the omission of something important?

As of this point in time, August 2025, which one is more intelligent: a humanoid robot equipped with various large models—capable even of performing simple tasks like folding clothes—or a dog? What are the current evaluation criteria? And will robots that score highly based on these criteria become the companions or slaves that humans desire in the future?
![Alt Text](img/IEEE_ROBOT.jpg)
<p align="center">Fig. AI-ROBOTS https://spectrum.ieee.org/ai-robots.</p>
